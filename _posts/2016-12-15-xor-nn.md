---
layout:     post
title:      "Simple Neural Network from scratch"
subtitle:   "in Python"
date:       2016-12-15 12:00:00
author:     "Exced"
header-img: "img/2016-12-06-im-alive/bg.png"
---

<p>
    We are going to build a simple neural network from scratch to recognize XOR function.
    This is the similar of "hello world" in neural net, but we'll build it without using any library (only numpy).
    <br> Then I'll give the TensorFlow equivalent which takes less than 10 lines of Python.
</p>

<p>
Here is what we want to be able to learn, giving 2 vectors A and B :
<table>
  <tr>
    <th>A</th>
    <th>B</th>
    <th>A XOR B</th>
  </tr>
  <tr>
    <td>0</td>
    <td>0</td>
    <td>0</td>
  </tr>
  <tr>
    <td>0</td>
    <td>1</td>
    <td>1</td>
  </tr>
  <tr>
    <td>1</td>
    <td>0</td>
    <td>1</td>
  </tr>
  <tr>
    <td>1</td>
    <td>1</td>
    <td>0</td>
  </tr>
</table>    

Since we know the real outputs of the function, we say that we do <b>supervised learning</b>
<br> 
</p>

<h3 class="subsection-heading"> Neural Net model </h3>


<h3 class="subsection-heading"> Code </h3>


<h4 class="subsubsection-heading"> Activation functions </h4>
<p>
We'll define 2 activation functions that work well in this problem : tanh and the sigmoid.

<h5 class="subsubsubsection-heading"> tanh </h5>

<a href="https://commons.wikimedia.org/wiki/File:Hyperbolic_Tangent.svg#/media/File:Hyperbolic_Tangent.svg">
<img class="center-image" src="https://upload.wikimedia.org/wikipedia/commons/thumb/8/87/Hyperbolic_Tangent.svg/1200px-Hyperbolic_Tangent.svg.png" alt="Hyperbolic Tangent.svg" height="400" width="400">
</a> 
</p>
{% highlight python %}
import numpy as np

def tanh(x):
    return np.tanh(x)

def tanh_p(x):
    return 1.0 - x**2
{% endhighlight %}

<h5 class="subsubsubsection-heading"> sigmoid </h5>

<a href="https://commons.wikimedia.org/wiki/File:Sigmoide.PNG#/media/File:Sigmoide.PNG">
<img class="center-image" src="https://upload.wikimedia.org/wikipedia/commons/9/9d/Sigmoide.PNG" alt="Sigmoide.PNG" height="400" width="400">
</a>

{% highlight python %}
def sigmoid(x):
    return 1.0/(1.0 + np.exp(-x))

def sigmoid_p(x):
    return sigmoid(x)*(1.0-sigmoid(x))
{% endhighlight %}

<p>
We can see see that these 2 functions are similarly good to discriminate values around 0.
</p>












